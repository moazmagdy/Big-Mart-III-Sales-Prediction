{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from scipy.stats import mode\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, PolynomialFeatures, Normalizer,MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, validation_curve, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('Train_UWu5bXk.csv')\n",
    "data_test = pd.read_csv('Test_u94Q5KV.csv')\n",
    "data_train['Train_Test'] = 'Train'\n",
    "data_test['Train_Test'] = 'Test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.concat([data_train, data_test], ignore_index= True, sort=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info(null_counts= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that, Item_Weight and Outlet_Size features have null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifying Categorical Features\n",
    "categorical_features = data.dtypes[data.dtypes == 'object'].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifying numeric Features\n",
    "numeric_features = data.dtypes[data.dtypes != 'object'].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Identifier coulmns from categorical features.\n",
    "categorical_features = [i for i in categorical_features if i not in ('Item_Identifier','Outlet_Identifier')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the frequency of each category in each feature\n",
    "for i in categorical_features:\n",
    "    print('Frequency of each category in variable: {}'.format(i))\n",
    "    print(data[i].value_counts(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In Item_Weight feature, we will replace Null values with the mean weight of each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the mean weight for each item\n",
    "item_avg_weight = data.pivot_table(values='Item_Weight',index='Item_Identifier', aggfunc = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary column for items whose weight is null.\n",
    "null_weight = data['Item_Weight'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.loc[null_weight,'Item_Weight'] = data.loc[null_weight,'Item_Identifier'].apply(lambda x: item_avg_weight.loc[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm null values are replace in Item_Weight\n",
    "data.Item_Weight.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. In Outlet_Size feature, we will replace null values with the most frequent Outlet_Size for the corresponding Outlet_Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the most frequent Outlet_Size for each Outlet_Type\n",
    "outlet_size_mode = data.pivot_table(values='Outlet_Size', columns='Outlet_Type', aggfunc = (lambda x: mode(x).mode[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary column to select rows where Outlet_Size is null.\n",
    "missing_size_bool = data.Outlet_Size.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill Outlet_Size null values with the most frequent Outlet_Size for Outlets of the same type.\n",
    "data.loc[missing_size_bool,'Outlet_Size'] = data.loc[missing_size_bool, 'Outlet_Type'].apply(lambda x: outlet_size_mode[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm no Null values in Outlet_Size\n",
    "data.Outlet_Size.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Different spelling of same level name in Item_Fat_Content feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Item_Fat_Content.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data.Item_Fat_Content == 'low fat') | (data.Item_Fat_Content == 'LF'),'Item_Fat_Content'] = 'Low Fat'\n",
    "data.loc[(data.Item_Fat_Content == 'reg'),'Item_Fat_Content'] = 'Regular'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. We have noticed that, items of type 'Household' have 'Item_Fat_Content' of 'Low Fat' which doesn't make sense!! So we repalce it by \"Non-edible\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data.Item_Type == 'Household'),'Item_Fat_Content'] = 'Non-edible'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check categories of Item_Fat_Content after modifications\n",
    "data.Item_Fat_Content.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data_clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Item_Visibilty, for some items the Item_Visibility is Zero which doesn't make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Items whose visibility is zero, their visibility is replaced by the average visibility of this item in all outlets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_avg_vis = pd.pivot_table(data, index= [data.Item_Identifier], values= ['Item_Visibility'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_vis = data.Item_Visibility == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[zero_vis,'Item_Visibility'] = data.loc[zero_vis,'Item_Identifier'].apply(lambda x: item_avg_vis.loc[x] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm no item visibility equals zero.\n",
    "(data.Item_Visibility == 0).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a new feature to represent the relative importance given to each product in different outlets. The importance of a product is expressed in terms of Item_visibility. Such that item visibility is compared to the average visibility of this item across all outlets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['visibility_ratio'] = data.apply(lambda x: x['Item_Visibility']/item_avg_vis.loc[x['Item_Identifier']],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create new feature for number of years since outlet establishment which is more meaningful than the date of establishment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this sales data for 2013, we will calculate the number of years from establishment to 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Outlet_Establishment_Year = 2013 - data.Outlet_Establishment_Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create a new feature to represent the relative price of each product with repsect to its mean price across all outlets. Since more expensive outlets may have lower sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_avg_price = pd.pivot_table(data, index= 'Item_Identifier', values='Item_MRP', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Item_MeanPrice_Ratio'] = data.apply(lambda x: x['Item_MRP']/item_avg_price.loc[x['Item_Identifier']], axis= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Item_Weight may don't have any thing to do with sales. But, it can be used to calculate the price per weight unit of the item. The price per weight unit is more precise indicator for item cost. We expect that as value of this indicator increases, the sales may decrease. We'll call this indicator (specific_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['specific_price'] = data.apply(lambda x: x['Item_MRP']/x['Item_Weight'], axis= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Create new feature to represent broader category of Item_Types, since we have 16 category and this is pretty much! we will replace it by 3 categories based on (Foods, Drinks, Unconsumables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first two characters in the Item_Identifier signifies each category.\n",
    "data['Item_Identifier'].apply(lambda x: x[:2]).unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Item_Type_combined'] = data['Item_Identifier'].apply(lambda x: x[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Item_Type_combined'] = data['Item_Type_combined'].map({'FD':'Food', 'DR':'Drinks', 'NC':'Non-Consumable'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Items may be categorized based on the sales\n",
    "# data.groupby('Item_Type')[['Item_Type','Item_Outlet_Sales']].sum().sort_values('Item_Outlet_Sales', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Convert categorical features into numeric features using LabelEncoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new feature Outlet to convert Outlet_Identifier into numeric feature and keep the original feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Outlet'] = data['Outlet_Identifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert other categorical features into numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_covert_num = data.dtypes[data.dtypes == 'object'].index.tolist()\n",
    "cat_covert_num = [i for i in cat_covert_num if i not in ('Item_Identifier','Outlet_Identifier','Item_Type','Train_Test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le ={} #Dictionary of the label encoders for all categorical features\n",
    "for col in cat_covert_num:\n",
    "    labelencoder = LabelEncoder()\n",
    "    le.update({col: labelencoder.fit(data[col])})\n",
    "    data[col] = labelencoder.fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unnecessary features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns= ['Item_Type', 'Outlet_Establishment_Year'], inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting dummies for categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data=data,columns=['Item_Fat_Content','Outlet_Size','Outlet_Location_Type','Outlet_Type','Item_Type_combined','Outlet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data again into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.loc[data['Train_Test'] == 'Train']\n",
    "test = data.loc[data['Train_Test'] == 'Test'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['Train_Test'], inplace= True)\n",
    "test.drop(columns=['index','Train_Test','Item_Outlet_Sales'], inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check features for which the difference between Min and Max is large.\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_normalize = ['Item_Weight','Item_Visibility','Item_MRP','specific_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "norm ={} #Dictionary of the MinMax Scalers for all features to be normalized.\n",
    "for i in features_to_normalize:\n",
    "    scaler = MinMaxScaler()\n",
    "    norm.update({i: scaler.fit(train[[i]])})\n",
    "    train[[i]] = scaler.transform(train[[i]])\n",
    "    if i == 'Item_Outlet_Sales':\n",
    "        break\n",
    "    else:    \n",
    "        test[[i]] = scaler.transform(test[[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export files as modified versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_engineered.csv', index=False)\n",
    "test.to_csv('test_engineered.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
